<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>تحليل الحالة النفسية للطالب</title>
  <style>
    html, body {
      margin: 0; padding: 0; background: #111; color: white; font-family: 'Arial', sans-serif;
      direction: rtl;
    }
    video, canvas {
      position: absolute; top: 0; left: 0; width: 100vw; height: 100vh; object-fit: cover; z-index: 0;
    }
    #statusBox {
      position: absolute; top: 10px; right: 10px; background: rgba(0,0,0,0.6);
      padding: 15px; border-radius: 12px; font-size: 20px; z-index: 10;
    }
    #teacherBox {
      position: absolute; bottom: 20px; right: 20px; background: linear-gradient(45deg, #2e8b57, #3cb371);
      color: white; padding: 20px; border-radius: 20px;
      box-shadow: 0 0 15px rgba(0,0,0,0.4); font-size: 18px; max-width: 400px; z-index: 10;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="canvas"></canvas>

  <div id="statusBox">الحالة النفسية: جاري التحليل...</div>
  <div id="teacherBox">الطالب: جاري التقييم...</div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const statusBox = document.getElementById('statusBox');
    const teacherBox = document.getElementById('teacherBox');

    const blinkHistory = Array(30).fill(false);

    function distance(a, b) {
      const dx = a.x - b.x;
      const dy = a.y - b.y;
      return Math.sqrt(dx*dx + dy*dy);
    }

    function analyzeState(landmarks) {
      const rightEyeOpen = distance(landmarks[159], landmarks[145]) > 0.015;
      const leftEyeOpen  = distance(landmarks[386], landmarks[374]) > 0.015;
      const mouthOpen    = distance(landmarks[13], landmarks[14]) > 0.035;

      const blinked = !rightEyeOpen && !leftEyeOpen;
      blinkHistory.shift();
      blinkHistory.push(blinked);

      const blinkRate = blinkHistory.filter(b => b).length / blinkHistory.length;
      const headStability = Math.abs(landmarks[10].x - landmarks[152].x) < 0.005;

      if (blinkRate < 0.1 && headStability && !mouthOpen) {
        return { state: "نائم أو شارد", advice: "الطالب يبدو مرهقًا — امنحه دقيقة راحة" };
      }
      if (mouthOpen && blinkRate > 0.3) {
        return { state: "متوتر أو قلق", advice: "الطالب متوتر — تحدث إليه بلطف" };
      }
      if (!mouthOpen && blinkRate > 0.4) {
        return { state: "تعب خفيف", advice: "الطالب بحاجة إلى تشجيع — قل له أحسنت!" };
      }
      if (!mouthOpen && rightEyeOpen && leftEyeOpen) {
        return { state: "مركز ومطمئن", advice: "الطالب مركز — استمر على هذا النهج!" };
      }
      return { state: "جارٍ التحليل", advice: "الطالب: جاري التقييم..." };
    }

    const faceMesh = new FaceMesh({ locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}` });
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });

    faceMesh.onResults(results => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

      if (results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        drawConnectors(ctx, landmarks, FACEMESH_TESSELATION, { color: 'rgba(0,255,0,0.3)', lineWidth: 1 });
        drawLandmarks(ctx, landmarks, { color: 'red', radius: 1.5 });

        const analysis = analyzeState(landmarks);
        statusBox.textContent = `الحالة النفسية: ${analysis.state}`;
        teacherBox.textContent = `الطالب: ${analysis.advice}`;
      } else {
        statusBox.textContent = "الحالة النفسية: لا يوجد وجه";
        teacherBox.textContent = "الطالب: غير ظاهر أمام الكاميرا";
      }
    });

    const camera = new Camera(video, {
      onFrame: async () => { await faceMesh.send({ image: video }); },
      width: 640,
      height: 480
    });
    camera.start();
  </script>
</body>
</html>